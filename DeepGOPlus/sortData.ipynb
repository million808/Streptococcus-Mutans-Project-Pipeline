{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import pandas as pd\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read In Excel File with Protein Abundancies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to Proteins.xlsx file\n",
    "excel_file_path = \"C:/Users/JoshK/OneDrive/Desktop/MMP/deepGOplus/Proteins.xlsx\"\n",
    "\n",
    "# Read the Excel sheets into a DataFrames\n",
    "increased_proteins = pd.read_excel(excel_file_path, sheet_name=\"Increase\", engine=\"openpyxl\")\n",
    "decreased_proteins = pd.read_excel(excel_file_path, sheet_name=\"Decrease\", engine=\"openpyxl\")\n",
    "\n",
    "# Save as CSV\n",
    "increased_proteins.to_csv(\"increased_proteins.csv\", index=False)\n",
    "decreased_proteins.to_csv(\"decreased_proteins.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get all Protein IDs and Sequences from the S. mutans Proteome"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Protein data has been saved to proteome_proteins_sequences.csv.\n"
     ]
    }
   ],
   "source": [
    "# Path to FASTA Sequence File\n",
    "fasta_file = \"C:/Users/JoshK/OneDrive/Desktop/MMP/deepGOplus/Streptococcus_mutans_proteome_UP000002512_2025_01_16.fasta\"\n",
    "\n",
    "# Variables for functions\n",
    "protein_data = []  # List to store rows with ID and sequence\n",
    "current_id = None  # Tracks the current protein ID being processed\n",
    "current_sequence = \"\"  # Tracks the sequence for the current protein\n",
    "\n",
    "# Open and read the FASTA file\n",
    "with open(fasta_file, \"r\") as file:\n",
    "    for line in file:\n",
    "        # Remove trailing whitespace\n",
    "        line = line.strip()\n",
    "        \n",
    "        if line.startswith(\">\"):\n",
    "            # If a new header line is found, save the previous ID and sequence\n",
    "            if current_id and current_sequence:\n",
    "                protein_data.append([current_id, current_sequence])\n",
    "            # Extract the protein ID from the header\n",
    "            current_id = line[4:10]  # Assuming IDs are at fixed positions 4-10\n",
    "            current_sequence = \"\"  # Reset the sequence for the new protein\n",
    "        elif current_id:\n",
    "            # Append the sequence lines to the current sequence\n",
    "            current_sequence += line\n",
    "\n",
    "    # Append the last protein's data\n",
    "    if current_id and current_sequence:\n",
    "        protein_data.append([current_id, current_sequence])\n",
    "\n",
    "# Write the data to a CSV file\n",
    "output_file = \"proteome_proteins_sequences.csv\"\n",
    "with open(output_file, \"w\", newline=\"\") as csvfile:\n",
    "    writer = csv.writer(csvfile)\n",
    "    # Write header row\n",
    "    writer.writerow([\"Accession\", \"Sequence\"])\n",
    "    # Write each protein's ID and sequence\n",
    "    writer.writerows(protein_data)\n",
    "\n",
    "print(f\"Protein data has been saved to {output_file}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Match Desired Proteins to sequenuences from Proteome"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in protein sequences from proteome, and dataframes for S. mutans\n",
    "proteome_proteins_sequences = pd.read_csv(\"proteome_proteins_sequences.csv\")\n",
    "\n",
    "increased_proteins = pd.read_csv(\"increased_proteins.csv\")\n",
    "decreased_proteins = pd.read_csv(\"decreased_proteins.csv\")\n",
    "# Merge the two DataFrames on \"Protein ID\"\n",
    "increased_sequences = pd.merge(increased_proteins, proteome_proteins_sequences, on=\"Accession\", how=\"inner\")\n",
    "decreased_sequences = pd.merge(decreased_proteins, proteome_proteins_sequences, on=\"Accession\", how=\"inner\")\n",
    "\n",
    "# Get just the ID and Sequences Columns\n",
    "increased_sequences = increased_sequences[[\"Accession\",\"Sequence\"]]\n",
    "decreased_sequences = decreased_sequences[[\"Accession\",\"Sequence\"]]\n",
    "# Save as CSV\n",
    "increased_sequences.to_csv(\"increased_sequences.csv\", index=False)\n",
    "decreased_sequences.to_csv(\"decreased_sequences.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create FASTA files for each"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FASTA file created at output.fasta\n"
     ]
    }
   ],
   "source": [
    "# Lists of protein IDs and sequences\n",
    "protein_ids = decreased_sequences[\"Accession\"]\n",
    "sequences = decreased_sequences[\"Sequence\"]\n",
    "# File path for the FASTA file\n",
    "fasta_file_path = \"output.fasta\"\n",
    "\n",
    "# Write protein IDs and sequences to a FASTA file\n",
    "with open(fasta_file_path, \"w\") as fasta_file:\n",
    "    for protein_id, sequence in zip(protein_ids, sequences):\n",
    "        fasta_file.write(f\">{protein_id}\\n{sequence}\\n\")\n",
    "\n",
    "print(f\"FASTA file created at {fasta_file_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reformat the deepGOplus CSV output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'C:/Users/JoshK/OneDrive/Desktop/MMP/deepGOplus/predictions_decreased_31_32.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 12\u001b[0m\n\u001b[0;32m      9\u001b[0m current_section \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;66;03m# Read the file line by line\u001b[39;00m\n\u001b[1;32m---> 12\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mfile_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mr\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m file:\n\u001b[0;32m     13\u001b[0m     reader \u001b[38;5;241m=\u001b[39m csv\u001b[38;5;241m.\u001b[39mreader(file, quotechar\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m, delimiter\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m,\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     14\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m line \u001b[38;5;129;01min\u001b[39;00m reader:\n",
      "File \u001b[1;32mc:\\Users\\JoshK\\anaconda3\\envs\\MMP\\Lib\\site-packages\\IPython\\core\\interactiveshell.py:324\u001b[0m, in \u001b[0;36m_modified_open\u001b[1;34m(file, *args, **kwargs)\u001b[0m\n\u001b[0;32m    317\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m {\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m}:\n\u001b[0;32m    318\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    319\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIPython won\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt let you open fd=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m by default \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    320\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mas it is likely to crash IPython. If you know what you are doing, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    321\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myou can use builtins\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m open.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    322\u001b[0m     )\n\u001b[1;32m--> 324\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mio_open\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'C:/Users/JoshK/OneDrive/Desktop/MMP/deepGOplus/predictions_decreased_31_32.csv'"
     ]
    }
   ],
   "source": [
    "# Variable for current file\n",
    "number = \"decreased_31_32\"\n",
    "# File path\n",
    "file_path = f\"C:/Users/JoshK/OneDrive/Desktop/MMP/deepGOplus/predictions_{number}.csv\"\n",
    "\n",
    "# Function variabbles\n",
    "data = []\n",
    "current_protein = None\n",
    "current_section = None\n",
    "\n",
    "# Read the file line by line\n",
    "with open(file_path, \"r\") as file:\n",
    "    reader = csv.reader(file, quotechar='\"', delimiter=\",\")\n",
    "    for line in reader:\n",
    "        if line[0].startswith((\"I\",\"Q\")):  # Protein identifier line\n",
    "            # Extract the 6-digit protein ID from specific positions in the string\n",
    "            current_protein = line[0][0:6]\n",
    "        elif line[0] in [\"Cellular Component\", \"Molecular Function\", \"Biological Process\"]:\n",
    "            current_section = line[0]\n",
    "        elif line[0].startswith(\"GO:\"):  # GO term line\n",
    "            go_id, description, score = line[0], line[1], line[2]\n",
    "            data.append({\n",
    "                \"Protein\": current_protein,\n",
    "                \"Section\": current_section,\n",
    "                \"GO_ID\": go_id,\n",
    "                \"Description\": description,\n",
    "                \"Score\": float(score)\n",
    "            })\n",
    "\n",
    "# Create a DataFrame\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Save to a CSV file\n",
    "df.to_csv(f\"parsed_predictions_{number}.csv\", index=False)\n",
    "\n",
    "# Group by Protein and Section, and take the top GO term by Score\n",
    "top_go_terms = df.loc[df.groupby([\"Protein\", \"Section\"])[\"Score\"].idxmax()]\n",
    "\n",
    "# Save to a CSV file if needed\n",
    "top_go_terms.to_csv(f\"top_go_terms_{number}.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Combine CSVs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All CSV files have been combined and saved as combined_top_predictions_increased.csv.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "# List of file paths to CSV files\n",
    "# files = [\n",
    "#     \"parsed_predictions_increased_1_10.csv\",\n",
    "#     \"parsed_predictions_increased_11_20.csv\",\n",
    "#     \"parsed_predictions_increased_21_30.csv\",\n",
    "#     \"parsed_predictions_increased_31_39.csv\"\n",
    "# ]\n",
    "# files = [\n",
    "#     \"parsed_predictions_decreased_1_10.csv\",\n",
    "#     \"parsed_predictions_decreased_11_20.csv\",\n",
    "#     \"parsed_predictions_decreased_21_30.csv\",\n",
    "#     \"parsed_predictions_decreased_31_32.csv\"\n",
    "# ]\n",
    "files = [\n",
    "    \"top_go_terms_increased_1_10.csv\",\n",
    "    \"top_go_terms_increased_11_20.csv\",\n",
    "    \"top_go_terms_increased_21_30.csv\",\n",
    "    \"top_go_terms_increased_31_39.csv\"\n",
    "]\n",
    "\n",
    "# Empty list for dataframes\n",
    "dataframes = []\n",
    "\n",
    "# Read each CSV file and append it to the list\n",
    "for file_path in files:\n",
    "    df = pd.read_csv(file_path)\n",
    "    dataframes.append(df)\n",
    "\n",
    "# Combine all DataFrames into a single DataFrame\n",
    "combined_df = pd.concat(dataframes, ignore_index=True)\n",
    "\n",
    "# Save the combined DataFrame to a new CSV file\n",
    "output_file = \"combined_top_predictions_increased.csv\"\n",
    "combined_df.to_csv(output_file, index=False)\n",
    "\n",
    "print(f\"All CSV files have been combined and saved as {output_file}.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MMP",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
